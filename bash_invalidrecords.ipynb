{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7730b9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148\n",
      "sbatch --array=39,41,67,68,69,74,76,77,94,95,124,142,200,229,230,231,235,238,239,256,257,258,286,288,295,296,305,391,392,393,397,398,400,401,418,419,466,524,525,553,554,555,560,562,563,580,581,582,607,611,685,715,716,717,721,722,742,743,773,790,854,877,878,879,883,884,886,887,904,905,906,910,953,1010,1039,1040,1041,1045,1046,1048,1049,1066,1067,1068,1201,1202,1203,1207,1210,1211,1228,1229,1230,1240,1258,1267,1277,1363,1364,1365,1369,1370,1372,1373,1390,1391,1402,1417,1420,1429,1438,1439,1498,1501,1503,1525,1526,1527,1531,1532,1534,1535,1552,1553,1554,1687,1688,1689,1693,1694,1696,1697,1714,1715,1716,1726,1745,1753,1762,1819,1820,1821,1849,1850,1851,1858,1877,1908 slurm.sh\n",
      "Unique prefixes and associated job IDs:\n",
      "network_4_0_33_1.4_0.5_10: [39, 525, 1821]\n",
      "network_4_0_33_1.4_0.6_5: [41]\n",
      "network_4_0_36_1.4_0.6_1: [67, 229, 391, 553, 715, 877, 1039, 1201, 1363, 1525, 1687, 1849]\n",
      "network_4_0_36_1.4_0.6_5: [68, 230, 392, 554, 716, 878, 1040, 1202, 1364, 1526, 1688, 1850]\n",
      "network_4_0_36_1.4_0.6_10: [69, 231, 393, 555, 717, 879, 1041, 1203, 1365, 1527, 1689, 1851]\n",
      "network_4_0_36_1.6_0.5_5: [74, 398, 560, 722, 884, 1046, 1370, 1532, 1694]\n",
      "network_4_0_36_1.6_0.6_1: [76, 238, 400, 562, 886, 1048, 1210, 1372, 1534, 1696, 1858]\n",
      "network_4_0_36_1.6_0.6_5: [77, 239, 401, 563, 887, 1049, 1211, 1373, 1535, 1697]\n",
      "network_4_0_39_1.4_0.6_1: [94, 256, 418, 580, 742, 904, 1066, 1228, 1390, 1552, 1714]\n",
      "network_4_0_39_1.4_0.6_5: [95, 257, 419, 581, 743, 905, 1067, 1229, 1391, 1553, 1715, 1877]\n",
      "network_4_0_42_1.4_0.7_1: [124, 286, 1258, 1420]\n",
      "network_4_0_45_1.2_0.7_1: [142, 466, 790, 1438, 1762]\n",
      "network_4_0_33_1.4_0.5_5: [200, 524, 1010, 1820]\n",
      "network_4_0_36_1.6_0.5_1: [235, 397, 721, 883, 1045, 1207, 1369, 1531, 1693]\n",
      "network_4_0_39_1.4_0.6_10: [258, 582, 906, 1068, 1230, 1554, 1716]\n",
      "network_4_0_42_1.4_0.7_10: [288, 1908]\n",
      "network_4_0_42_1.6_0.7_1: [295, 1267, 1429, 1753]\n",
      "network_4_0_42_1.6_0.7_5: [296]\n",
      "network_4_0_45_1.2_0.7_5: [305, 953, 1277, 1439]\n",
      "network_4_0_42_1.4_0.6_1: [607, 1417]\n",
      "network_4_0_42_1.4_0.7_5: [611, 773, 1745]\n",
      "network_4_0_33_1.4_0.5_1: [685, 1819]\n",
      "network_4_0_33_1.4_0.7_5: [854]\n",
      "network_4_0_39_1.6_0.5_1: [910]\n",
      "network_4_0_39_1.6_0.7_1: [1240, 1402, 1726]\n",
      "network_4_0_33_1.4_0.6_1: [1498]\n",
      "network_4_0_33_1.4_0.7_1: [1501]\n",
      "network_4_0_33_1.4_0.7_10: [1503]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load the Excel file and the \"Invalid Records\" sheet\n",
    "df = pd.read_excel(\"src/results/aggregated_results.xlsx\", sheet_name=\"Invalid Records\", header=None)\n",
    "\n",
    "# Convert records to string and strip whitespace\n",
    "records = df[0].astype(str).str.strip()\n",
    "\n",
    "# Extract the last number from each record\n",
    "# Assuming the record format is like: network_4_0_39_1.6_0.7_1_1078\n",
    "last_numbers = df[0].astype(str).apply(lambda x: x.strip().split('_')[-1])\n",
    "\n",
    "# Convert to sorted unique integers\n",
    "numbers = sorted(set(map(int, last_numbers)))\n",
    "\n",
    "# Join them into a comma-separated string\n",
    "array_values = \",\".join(map(str, numbers))\n",
    "\n",
    "# Construct the sbatch command\n",
    "sbatch_command = f\"sbatch --array={array_values} slurm.sh\"\n",
    "print(len(numbers))\n",
    "print(sbatch_command)\n",
    "\n",
    "# Extract prefix and ID from each record\n",
    "prefix_id_pairs = records.apply(lambda x: ('_'.join(x.split('_')[:-1]), int(x.split('_')[-1])))\n",
    "\n",
    "# Group IDs by prefix\n",
    "prefix_to_ids = defaultdict(set)\n",
    "for prefix, job_id in prefix_id_pairs:\n",
    "    prefix_to_ids[prefix].add(job_id)\n",
    "\n",
    "# Optional: sort the IDs for each prefix\n",
    "prefix_to_ids = {prefix: sorted(list(ids)) for prefix, ids in prefix_to_ids.items()}\n",
    "\n",
    "# Print the mapping\n",
    "print(\"Unique prefixes and associated job IDs:\")\n",
    "for prefix, ids in prefix_to_ids.items():\n",
    "    print(f\"{prefix}: {ids}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
